{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Custom openWakeWord Model\n",
    "\n",
    "Windows-compatible version of the openWakeWord training notebook.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Setup the Jupyter kernel (one-time)\n",
    "\n",
    "```bash\n",
    "uv add ipykernel --dev\n",
    "uv run python -m ipykernel install --user --name voice-gateway\n",
    "```\n",
    "\n",
    "### Run in VS Code\n",
    "\n",
    "1. Open this notebook in VS Code\n",
    "2. Click **Select Kernel** (top right) â†’ **voice-gateway**\n",
    "3. Run the cells!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True for NVIDIA GPU support (requires CUDA installed)\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install PyTorch with CUDA support from PyTorch's index\n",
    "if USE_GPU:\n",
    "    print(\"Installing PyTorch with CUDA support...\")\n",
    "    subprocess.run([\n",
    "        \"uv\", \"pip\", \"install\",\n",
    "        \"torch>=2.0,<2.6\", \"torchaudio\",\n",
    "        \"--index-url\", \"https://download.pytorch.org/whl/cu124\"\n",
    "    ], check=True)\n",
    "else:\n",
    "    print(\"Installing PyTorch (CPU only)...\")\n",
    "    subprocess.run([\"uv\", \"pip\", \"install\", \"torch>=2.0,<2.6\", \"torchaudio\"], check=True)\n",
    "\n",
    "# Verify GPU is available\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU detected - will use CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other dependencies\n",
    "deps = [\n",
    "    \"webrtcvad\",\n",
    "    \"piper-tts\",\n",
    "    \"piper-phonemize-cross\",\n",
    "    \"numpy\",\n",
    "    \"scipy\",\n",
    "    \"tqdm\",\n",
    "    \"datasets==2.14.6\",\n",
    "    \"pyyaml\",\n",
    "    \"onnxruntime\",\n",
    "    \"onnx\",\n",
    "    \"onnx2tf\",\n",
    "    \"onnxsim\",\n",
    "    \"onnx-graphsurgeon\",\n",
    "    \"sng4onnx\",\n",
    "    \"pronouncing\",\n",
    "    \"deep-phonemizer\",\n",
    "    \"mutagen\",\n",
    "    \"torchinfo\",\n",
    "    \"torchmetrics\",\n",
    "    \"speechbrain==0.5.14\",\n",
    "    \"audiomentations\",\n",
    "    \"torch-audiomentations\",\n",
    "    \"acoustics\",\n",
    "    \"requests\",\n",
    "    \"ipywidgets\",\n",
    "]\n",
    "\n",
    "# Install dependencies one by one to see which fail\n",
    "failed = []\n",
    "for dep in deps:\n",
    "    result = subprocess.run([\"uv\", \"pip\", \"install\", dep], capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        failed.append(dep)\n",
    "        print(f\"Failed: {dep}\")\n",
    "    else:\n",
    "        print(f\"Installed: {dep}\")\n",
    "\n",
    "if failed:\n",
    "    print(f\"\\nWarning: Failed to install: {failed}\")\n",
    "    print(\"Some features may not work, but core training should still function.\")\n",
    "else:\n",
    "    print(\"\\nAll dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "SCRIPT_DIR = Path(\".\").resolve()\n",
    "print(f\"Working directory: {SCRIPT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone piper-sample-generator\n",
    "PIPER_DIR = SCRIPT_DIR / \"piper-sample-generator\"\n",
    "\n",
    "if not PIPER_DIR.exists():\n",
    "    print(\"Cloning piper-sample-generator...\")\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/rhasspy/piper-sample-generator\"], cwd=SCRIPT_DIR, check=True)\n",
    "    subprocess.run([\"git\", \"checkout\", \"213d4d5\"], cwd=PIPER_DIR, check=True)\n",
    "else:\n",
    "    print(\"piper-sample-generator already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download piper model\n",
    "MODELS_DIR = PIPER_DIR / \"models\"\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "MODEL_PATH = MODELS_DIR / \"en_US-libritts_r-medium.pt\"\n",
    "\n",
    "if not MODEL_PATH.exists():\n",
    "    print(\"Downloading piper model...\")\n",
    "    url = \"https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    total = int(response.headers.get(\"content-length\", 0))\n",
    "    with open(MODEL_PATH, \"wb\") as f:\n",
    "        with tqdm(total=total, unit=\"B\", unit_scale=True, desc=\"Piper model\") as pbar:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "                pbar.update(len(chunk))\n",
    "else:\n",
    "    print(\"Piper model already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone openwakeword\n",
    "OWW_DIR = SCRIPT_DIR / \"openwakeword\"\n",
    "\n",
    "if not OWW_DIR.exists():\n",
    "    print(\"Cloning openwakeword...\")\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/dscripka/openwakeword\"], cwd=SCRIPT_DIR, check=True)\n",
    "else:\n",
    "    print(\"openwakeword already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download openwakeword models\n",
    "OWW_MODELS_DIR = OWW_DIR / \"openwakeword\" / \"resources\" / \"models\"\n",
    "OWW_MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_urls = {\n",
    "    \"embedding_model.onnx\": \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx\",\n",
    "    \"embedding_model.tflite\": \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite\",\n",
    "    \"melspectrogram.onnx\": \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx\",\n",
    "    \"melspectrogram.tflite\": \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite\",\n",
    "}\n",
    "\n",
    "for filename, url in model_urls.items():\n",
    "    filepath = OWW_MODELS_DIR / filename\n",
    "    if not filepath.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    else:\n",
    "        print(f\"{filename} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Wake Word Pronunciation\n",
    "\n",
    "Before training, verify the TTS pronounces your wake word correctly.\n",
    "\n",
    "**Tips:**\n",
    "- If pronunciation is wrong, spell it phonetically with underscores: `\"hey_seer_e\"` for \"hey siri\"\n",
    "- Spell out numbers: `\"two\"` not `\"2\"`\n",
    "- Avoid punctuation except `?` and `!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your wake word here!\n",
    "TARGET_WORD = \"Seraphina\"  # Change this to your desired wake word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if str(PIPER_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PIPER_DIR))\n",
    "\n",
    "from generate_samples import generate_samples\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def test_pronunciation(text: str):\n",
    "    \"\"\"Generate and play a test sample.\"\"\"\n",
    "    generate_samples(\n",
    "        text=text,\n",
    "        max_samples=1,\n",
    "        length_scales=[1.1],\n",
    "        noise_scales=[0.7],\n",
    "        noise_scale_ws=[0.7],\n",
    "        output_dir=str(SCRIPT_DIR),\n",
    "        batch_size=1,\n",
    "        auto_reduce_batch_size=True,\n",
    "        file_names=[\"test_generation.wav\"],\n",
    "    )\n",
    "    display(Audio(str(SCRIPT_DIR / \"test_generation.wav\"), autoplay=True))\n",
    "\n",
    "test_pronunciation(TARGET_WORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Training Data\n",
    "\n",
    "This downloads:\n",
    "- Pre-computed openWakeWord features (~16GB) - for negative examples\n",
    "- Validation set features (~180MB) - for false positive estimation\n",
    "\n",
    "**Note:** The 16GB download takes a while. You can skip it with `SKIP_LARGE_DOWNLOAD = True` but training quality will be lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_LARGE_DOWNLOAD = False  # Set to True to skip the 16GB download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download validation features (small, always download)\n",
    "VAL_PATH = SCRIPT_DIR / \"validation_set_features.npy\"\n",
    "\n",
    "if not VAL_PATH.exists():\n",
    "    print(\"Downloading validation features...\")\n",
    "    url = \"https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    total = int(response.headers.get(\"content-length\", 0))\n",
    "    with open(VAL_PATH, \"wb\") as f:\n",
    "        with tqdm(total=total, unit=\"B\", unit_scale=True, desc=\"Validation features\") as pbar:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "                pbar.update(len(chunk))\n",
    "else:\n",
    "    print(\"Validation features already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training features (large)\n",
    "FEATURES_PATH = SCRIPT_DIR / \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"\n",
    "\n",
    "if SKIP_LARGE_DOWNLOAD:\n",
    "    print(\"Skipping large feature download (training quality will be reduced)\")\n",
    "elif not FEATURES_PATH.exists():\n",
    "    print(\"Downloading training features (16GB, this will take a while)...\")\n",
    "    url = \"https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    total = int(response.headers.get(\"content-length\", 0))\n",
    "    with open(FEATURES_PATH, \"wb\") as f:\n",
    "        with tqdm(total=total, unit=\"B\", unit_scale=True, desc=\"Training features\") as pbar:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "                pbar.update(len(chunk))\n",
    "else:\n",
    "    print(\"Training features already downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure Training\n",
    "\n",
    "Adjust these parameters:\n",
    "- `N_SAMPLES`: Number of synthetic examples (1000 is quick, 30000-50000 is better)\n",
    "- `N_STEPS`: Training steps (10000 is quick, more is better)\n",
    "- `FALSE_ACTIVATION_PENALTY`: Higher = fewer false activations but may miss quiet/noisy speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 1000\n",
    "N_STEPS = 10000\n",
    "FALSE_ACTIVATION_PENALTY = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load default config\n",
    "with open(OWW_DIR / \"examples\" / \"custom_model.yml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Modify config\n",
    "config[\"target_phrase\"] = [TARGET_WORD]\n",
    "config[\"model_name\"] = TARGET_WORD.replace(\" \", \"_\")\n",
    "config[\"n_samples\"] = N_SAMPLES\n",
    "config[\"n_samples_val\"] = max(500, N_SAMPLES // 10)\n",
    "config[\"steps\"] = N_STEPS\n",
    "config[\"target_accuracy\"] = 0.5\n",
    "config[\"target_recall\"] = 0.25\n",
    "config[\"output_dir\"] = str(SCRIPT_DIR / \"my_custom_model\")\n",
    "config[\"max_negative_weight\"] = FALSE_ACTIVATION_PENALTY\n",
    "\n",
    "# Data paths\n",
    "config[\"background_paths\"] = []  # Empty - we're using pre-computed features\n",
    "config[\"false_positive_validation_data_path\"] = str(VAL_PATH)\n",
    "\n",
    "if FEATURES_PATH.exists():\n",
    "    config[\"feature_data_files\"] = {\"ACAV100M_sample\": str(FEATURES_PATH)}\n",
    "else:\n",
    "    config[\"feature_data_files\"] = {}\n",
    "\n",
    "# Save config\n",
    "CONFIG_PATH = SCRIPT_DIR / \"my_model.yaml\"\n",
    "with open(CONFIG_PATH, \"w\") as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(f\"Config saved to: {CONFIG_PATH}\")\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Target word: {TARGET_WORD}\")\n",
    "print(f\"  Samples: {N_SAMPLES}\")\n",
    "print(f\"  Steps: {N_STEPS}\")\n",
    "print(f\"  Output: {config['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "This runs three steps:\n",
    "1. **Generate clips** - Create synthetic audio of your wake word\n",
    "2. **Augment clips** - Add noise, reverb, etc. for robustness\n",
    "3. **Train model** - Train the neural network\n",
    "\n",
    "With default settings, this takes 30-60 minutes on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCRIPT = OWW_DIR / \"openwakeword\" / \"train.py\"\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Step 1: Generating training clips\")\n",
    "print(\"=\" * 50)\n",
    "subprocess.run([sys.executable, str(TRAIN_SCRIPT), \"--training_config\", str(CONFIG_PATH), \"--generate_clips\"], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Step 2: Augmenting clips\")\n",
    "print(\"=\" * 50)\n",
    "subprocess.run([sys.executable, str(TRAIN_SCRIPT), \"--training_config\", str(CONFIG_PATH), \"--augment_clips\"], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Step 3: Training model\")\n",
    "print(\"=\" * 50)\n",
    "subprocess.run([sys.executable, str(TRAIN_SCRIPT), \"--training_config\", str(CONFIG_PATH), \"--train_model\"], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Done!\n",
    "\n",
    "Your trained model is in the `my_custom_model` folder. You'll find:\n",
    "- `{TARGET_WORD}.onnx` - ONNX format model\n",
    "- `{TARGET_WORD}.tflite` - TensorFlow Lite format model\n",
    "\n",
    "Copy the `.onnx` or `.tflite` file to your wakewords folder to use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(config[\"output_dir\"])\n",
    "print(f\"\\nTraining complete! Model files:\")\n",
    "for f in OUTPUT_DIR.glob(\"*\"):\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Copy to wakewords folder\n",
    "import shutil\n",
    "\n",
    "WAKEWORD_DIR = SCRIPT_DIR.parent / \"wakewords\" / \"seraphina\"\n",
    "WAKEWORD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = TARGET_WORD.replace(\" \", \"_\")\n",
    "for ext in [\".onnx\", \".tflite\"]:\n",
    "    src = OUTPUT_DIR / f\"{model_name}{ext}\"\n",
    "    if src.exists():\n",
    "        dst = WAKEWORD_DIR / f\"{model_name}{ext}\"\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\"Copied {src.name} to {dst}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
